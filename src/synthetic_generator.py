# -*- coding: utf-8 -*-
"""
SENTETÄ°K VERÄ° ÃœRETÄ°CÄ° V3 - INCREMENTAL SAVE
============================================
Groq API - Her baÅŸarÄ±lÄ± Ã¼retimde kaydet (rate limit korumasÄ±)
"""

import json
import re
import time
import os
from pathlib import Path
from collections import Counter
from dotenv import load_dotenv
import requests

script_dir = Path(__file__).parent
project_dir = script_dir.parent
load_dotenv(project_dir / ".env")

GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")
GROQ_URL = "https://api.groq.com/openai/v1/chat/completions"

ALT_KONU_SABLONLARI = {
    "Ã‡ok AnlamlÄ±lÄ±k": {"aciklama": "Bir sÃ¶zcÃ¼k farklÄ± cÃ¼mlelerde farklÄ± anlamlarda kullanÄ±lÄ±r."},
    "Deyim": {"aciklama": "Deyimler kalÄ±plaÅŸmÄ±ÅŸ sÃ¶z Ã¶bekleridir."},
    "Sebep-SonuÃ§": {"aciklama": "Bir olayÄ±n nedeni veya sonucu sorulur."},
    "Fiilimsiler": {"aciklama": "Fiil kÃ¶kÃ¼nden tÃ¼reyen isim, sÄ±fat veya zarf gibi sÃ¶zcÃ¼kler."},
    "Noktalama": {"aciklama": "Noktalama iÅŸaretlerinin doÄŸru kullanÄ±mÄ±."},
    "Ã–znel-Nesnel": {"aciklama": "Ã–znel yargÄ± kiÅŸisel gÃ¶rÃ¼ÅŸ, nesnel yargÄ± kanÄ±tlanabilir bilgi."},
    "AnlatÄ±m BiÃ§imi": {"aciklama": "Ã–ykÃ¼leme, betimleme, aÃ§Ä±klama veya tartÄ±ÅŸma."},
    "KoÅŸul": {"aciklama": "KoÅŸul anlamÄ± taÅŸÄ±yan cÃ¼mleler: -sa/-se, eÄŸer."},
    "YazÄ±m YanlÄ±ÅŸÄ±": {"aciklama": "TDK yazÄ±m kurallarÄ±na uygunluk."},
    "Ana DÃ¼ÅŸÃ¼nce": {"aciklama": "Metnin ana fikri."},
    "BaÅŸlÄ±k Bulma": {"aciklama": "Metnin iÃ§eriÄŸine uygun baÅŸlÄ±k."},
}

TEMALAR = ["Teknoloji", "Ã‡evre", "SaÄŸlÄ±k", "Okuma", "Bilim", "Spor", "Ä°letiÅŸim"]

def count_words(text):
    return len(re.findall(r'\b\w+\b', text or "", re.UNICODE))

def call_groq(prompt):
    """Groq API Ã§aÄŸrÄ±sÄ± - tek deneme."""
    try:
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": "llama-3.3-70b-versatile",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.8,
            "max_tokens": 1200,
        }
        response = requests.post(GROQ_URL, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            return response.json()["choices"][0]["message"]["content"]
        elif response.status_code == 429:
            return "RATE_LIMIT"
        else:
            return None
    except:
        return None

def get_konu(alt_konu):
    mapping = {
        "Ana DÃ¼ÅŸÃ¼nce": "Paragraf", "BaÅŸlÄ±k Bulma": "Paragraf", "AnlatÄ±m BiÃ§imi": "Paragraf",
        "Sebep-SonuÃ§": "CÃ¼mlede Anlam", "KoÅŸul": "CÃ¼mlede Anlam", "Ã–znel-Nesnel": "CÃ¼mlede Anlam",
        "Deyim": "CÃ¼mlede Anlam", "Fiilimsiler": "Dil Bilgisi", "Ã‡ok AnlamlÄ±lÄ±k": "SÃ¶zcÃ¼kte Anlam",
        "Noktalama": "YazÄ±m KurallarÄ±", "YazÄ±m YanlÄ±ÅŸÄ±": "YazÄ±m KurallarÄ±",
    }
    return mapping.get(alt_konu, "Paragraf")

def generate_one(alt_konu):
    """Tek soru Ã¼ret."""
    import random
    tema = random.choice(TEMALAR)
    aciklama = ALT_KONU_SABLONLARI.get(alt_konu, {}).get("aciklama", "")
    
    prompt = f"""Sen MEB LGS 8. sÄ±nÄ±f TÃ¼rkÃ§e soru yazarÄ±sÄ±n.

GÃ–REV: {alt_konu} konusunda LGS sorusu yaz.
KONU AÃ‡IKLAMASI: {aciklama}
TEMA: {tema}

KURALLAR:
1. SADECE TÃœRKÃ‡E yaz!
2. Metin EN AZ 80 kelime, EN FAZLA 150 kelime olmalÄ±!
3. Paragraf ÅŸeklinde yaz, numaralÄ± cÃ¼mle KULLANMA!
4. 4 ÅŸÄ±k olmalÄ± (A, B, C, D)
5. DoÄŸru cevabÄ± belirt

Ã‡IKTI (TAM BU JSON FORMATINDA):
{{"metin": "80-150 kelimelik uzun paragraf buraya", "soru": "Soru metni", "sik_a": "A ÅŸÄ±kkÄ±", "sik_b": "B ÅŸÄ±kkÄ±", "sik_c": "C ÅŸÄ±kkÄ±", "sik_d": "D ÅŸÄ±kkÄ±", "dogru_cevap": "A"}}

SADECE JSON dÃ¶ndÃ¼r!"""

    response = call_groq(prompt)
    
    if response == "RATE_LIMIT":
        return "RATE_LIMIT"
    if not response:
        return None
    
    try:
        start = response.find('{')
        end = response.rfind('}')
        if start != -1 and end != -1:
            data = json.loads(response[start:end+1])
            metin = data.get("metin", "")
            wc = count_words(metin)
            
            # Daha esnek kelime aralÄ±ÄŸÄ±: 40-200
            if 40 <= wc <= 200:
                return {
                    "user": f"Konu: {get_konu(alt_konu)}\nAlt Konu: {alt_konu}",
                    "assistant": json.dumps(data, ensure_ascii=False),
                    "wc": wc
                }
    except:
        pass
    return None

def run_generator(train_path, output_path, target_per_alt=5):
    """Ana dÃ¶ngÃ¼ - incremental save."""
    
    # Mevcut sayÄ±larÄ± hesapla
    data = []
    with open(train_path, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data.append(json.loads(line.strip()))
            except:
                pass
    
    counts = Counter()
    for ex in data:
        user = ex.get("user", "")
        if "Alt Konu:" in user:
            ak = user.split("Alt Konu:")[1].split("\n")[0].strip()
            counts[ak] += 1
    
    # Eksikleri belirle
    print(f"{'='*50}")
    print(f"MEVCUT DURUM:")
    needs = {}
    for ak in ALT_KONU_SABLONLARI:
        c = counts.get(ak, 0)
        need = max(0, target_per_alt)
        needs[ak] = need
        print(f"   {ak}: {c}")
    
    # Ãœretim
    print(f"\n{'='*50}")
    print(f"ÃœRETÄ°M (her alt konu iÃ§in {target_per_alt})")
    
    generated = []
    
    for alt_konu in ALT_KONU_SABLONLARI:
        print(f"\nğŸ“ {alt_konu}:")
        success = 0
        attempts = 0
        max_attempts = target_per_alt * 5
        
        while success < target_per_alt and attempts < max_attempts:
            attempts += 1
            result = generate_one(alt_konu)
            
            if result == "RATE_LIMIT":
                print(f"   â³ Rate limit, 10sn bekleniyor...")
                time.sleep(10)
                continue
            
            if result:
                generated.append(result)
                success += 1
                print(f"   âœ… {success}/{target_per_alt} ({result['wc']} kelime)")
                
                # Her baÅŸarÄ±lÄ± Ã¼retimde kaydet
                with open(output_path, 'a', encoding='utf-8') as f:
                    save = {"user": result["user"], "assistant": result["assistant"]}
                    f.write(json.dumps(save, ensure_ascii=False) + '\n')
            
            time.sleep(1)  # Rate limit korumasÄ±
        
        print(f"   TamamlandÄ±: {success}/{target_per_alt}")
    
    print(f"\n{'='*50}")
    print(f"âœ… TOPLAM: {len(generated)} Ã¶rnek Ã¼retildi")
    print(f"   Kaydedildi: {output_path}")

if __name__ == "__main__":
    train_path = project_dir / "data" / "v11_filtered" / "train.jsonl"
    output_path = project_dir / "data" / "synthetic_v1.jsonl"
    
    if not GROQ_API_KEY:
        print("âŒ GROQ_API_KEY bulunamadÄ±!")
        exit(1)
    
    # Eski dosyayÄ± temizle
    if output_path.exists():
        output_path.unlink()
    
    print(f"ğŸ”‘ Groq API: ...{GROQ_API_KEY[-8:]}")
    
    # Her alt konu iÃ§in 5 Ã¶rnek Ã¼ret (toplam ~55)
    run_generator(train_path, output_path, target_per_alt=5)
