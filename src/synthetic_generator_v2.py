# -*- coding: utf-8 -*-
"""
PROFESYONEL SENTETÄ°K VERÄ° ÃœRETÄ°CÄ°SÄ° v2
======================================
RAG V3 Entegreli, Dengeli DaÄŸÄ±lÄ±mlÄ±, Kalite Validasyonlu
"""

import json
import re
import time
import os
from pathlib import Path
from collections import Counter
from dotenv import load_dotenv
import requests

# Load environment
script_dir = Path(__file__).parent
project_dir = script_dir.parent
load_dotenv(project_dir / ".env")

# API Configuration
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")
GROQ_URL = "https://api.groq.com/openai/v1/chat/completions"

# RAG V3 KurallarÄ± (hardcoded for reliability)
QUESTION_TYPE_SPECS = {
    "Paragraf_Ana DÃ¼ÅŸÃ¼nce": {
        "min_words": 120, "max_words": 220,
        "numbered": False,
        "highlights": False,
        "description": "Metnin ana fikri, temel mesajÄ±"
    },
    "Paragraf_BaÅŸlÄ±k Bulma": {
        "min_words": 120, "max_words": 220,
        "numbered": False,
        "highlights": False,
        "description": "Metne uygun baÅŸlÄ±k bulma"
    },
    "Paragraf_AnlatÄ±m BiÃ§imi": {
        "min_words": 120, "max_words": 220,
        "numbered": False,
        "highlights": False,
        "description": "AnlatÄ±m tÃ¼rÃ¼ (Ã¶ykÃ¼leme, betimleme, aÃ§Ä±klama, tartÄ±ÅŸma)"
    },
    "CÃ¼mlede Anlam_Sebep-SonuÃ§": {
        "min_words": 80, "max_words": 150,
        "numbered": False,
        "highlights": False,
        "description": "Neden-sonuÃ§ iliÅŸkisi"
    },
    "CÃ¼mlede Anlam_KoÅŸul": {
        "min_words": 80, "max_words": 150,
        "numbered": False,
        "highlights": False,
        "description": "KoÅŸul anlamÄ± (-sa/-se, eÄŸer)"
    },
    "CÃ¼mlede Anlam_Ã–znel-Nesnel": {
        "min_words": 80, "max_words": 150,
        "numbered": False,
        "highlights": False,
        "description": "Ã–znel (kiÅŸisel) vs Nesnel (kanÄ±tlanabilir) yargÄ±"
    },
    "CÃ¼mlede Anlam_Deyim": {
        "min_words": 80, "max_words": 150,
        "numbered": False,
        "highlights": False,
        "description": "Deyimlerin anlamÄ±"
    },
    "SÃ¶zcÃ¼kte Anlam_Ã‡ok AnlamlÄ±lÄ±k": {
        "min_words": 40, "max_words": 80,
        "numbered": True,  # NumaralÄ± cÃ¼mleler
        "highlights": True,  # Hedef kelime vurgusu
        "description": "Bir kelimenin farklÄ± anlamlarÄ±"
    },
    "SÃ¶zcÃ¼kte Anlam_EÅŸ AnlamlÄ±lÄ±k": {
        "min_words": 40, "max_words": 80,
        "numbered": True,
        "highlights": True,
        "description": "EÅŸ anlamlÄ± kelimeler"
    },
    "SÃ¶zcÃ¼kte Anlam_ZÄ±t AnlamlÄ±lÄ±k": {
        "min_words": 40, "max_words": 80,
        "numbered": True,
        "highlights": True,
        "description": "ZÄ±t anlamlÄ± kelimeler"
    },
    "Dil Bilgisi_Fiilimsiler": {
        "min_words": 100, "max_words": 180,
        "numbered": False,
        "highlights": False,
        "description": "Ä°sim-fiil, sÄ±fat-fiil, zarf-fiil"
    },
    "Dil Bilgisi_Kelime TÃ¼rleri": {
        "min_words": 100, "max_words": 180,
        "numbered": False,
        "highlights": False,
        "description": "Ä°sim, fiil, sÄ±fat, zarf, zamir vb."
    },
    "YazÄ±m KurallarÄ±_Noktalama": {
        "min_words": 80, "max_words": 150,
        "numbered": False,
        "highlights": False,
        "description": "Noktalama iÅŸaretleri"
    },
    "YazÄ±m KurallarÄ±_YazÄ±m YanlÄ±ÅŸÄ±": {
        "min_words": 80, "max_words": 150,
        "numbered": False,
        "highlights": False,
        "description": "YazÄ±m hatalarÄ±"
    },
}

TEMALAR = [
    "Teknoloji", "Ã‡evre", "SaÄŸlÄ±k", "EÄŸitim", "Spor", 
    "Sanat", "Bilim", "Tarih", "Edebiyat", "MÃ¼zik",
    "DoÄŸa", "Hayvanlar", "Uzay", "Ä°letiÅŸim", "Aile"
]

def count_words(text):
    """Kelime sayÄ±sÄ±nÄ± hesapla."""
    return len(re.findall(r'\b\w+\b', text or "", re.UNICODE))

def call_groq_api(prompt, max_retries=3):
    """Groq API Ã§aÄŸrÄ±sÄ± with retry."""
    for attempt in range(max_retries):
        try:
            headers = {
                "Authorization": f"Bearer {GROQ_API_KEY}",
                "Content-Type": "application/json"
            }
            payload = {
                "model": "llama-3.3-70b-versatile",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.85,  # Diversity iÃ§in yÃ¼ksek
                "max_tokens": 1500,
            }
            
            response = requests.post(GROQ_URL, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                return response.json()["choices"][0]["message"]["content"]
            elif response.status_code == 429:
                wait_time = (attempt + 1) * 10
                print(f"   â³ Rate limit, {wait_time}sn bekleniyor...")
                time.sleep(wait_time)
                continue
            else:
                print(f"   âŒ API Error: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"   âŒ Exception: {str(e)}")
            if attempt < max_retries - 1:
                time.sleep(5)
                continue
            return None
    
    return None

def build_professional_prompt(konu, alt_konu, tema, spec):
    """
    PROFESYONEL PROMPT - RAG V3 Stratejileri Dahil
    
    Multi-shot learning + explicit rules + quality emphasis
    """
    
    min_w = spec["min_words"]
    max_w = spec["max_words"]
    numbered = spec["numbered"]
    highlights = spec["highlights"]
    desc = spec["description"]
    
    prompt = f"""Sen MEB LGS 8. sÄ±nÄ±f TÃ¼rkÃ§e sÄ±navlarÄ± iÃ§in PROFESYONEL soru hazÄ±rlayan bir uzman yazarsÄ±n.

## GÃ–REV
Konu: {konu}
Alt Konu: {alt_konu} ({desc})
Tema: {tema}

## KESÄ°N KURALLAR (UYMAYANLAR REDDEDÄ°LÄ°R!)

### 1. Metin YapÄ±sÄ±
- Kelime sayÄ±sÄ±: TAM OLARAK {min_w}-{max_w} kelime arasÄ±
- Format: {"NUMARALI cÃ¼mleler (I. II. III. IV.)" if numbered else "PARAGRAF (numaralÄ± cÃ¼mle KULLANMA)"}
{"- Hedef kelime: TÄ±rnak iÃ§inde vurgula (Ã¶rn: 'gÃ¶z')" if highlights else ""}
- SADECE TÃœRKÃ‡E! Ã‡ince, Ä°ngilizce, ArapÃ§a YASAK!

### 2. Metin Kalitesi
- LGS seviyesine uygun âœ…
- AkÄ±cÄ± ve doÄŸal dil âœ…
- Gramere uygun âœ…
- Ä°Ã§erik temaya uygun âœ…
{"- KELÄ°ME SAYISI Ã‡OK Ã–NEMLÄ°: " + str(min_w) + "-" + str(max_w) + " arasÄ± olmalÄ±!" if True else ""}

### 3. Soru Kalitesi
- Metinle doÄŸrudan ilgili âœ…
- Tek doÄŸru cevap âœ…
- 4 ÅŸÄ±k (A, B, C, D) âœ…
- Ã‡eldiriciler mantÄ±klÄ± ama yanlÄ±ÅŸ âœ…
- DoÄŸru cevap metinde aÃ§Ä±kÃ§a var âœ…

## Ã‡ELDÄ°RÄ°CÄ° TAKTÄ°KLERÄ°

**Etkili Ã§eldiriciler:**
1. Metinde geÃ§en ama soruyla ilgisiz bilgi
2. DoÄŸruya yakÄ±n ama eksik/fazla bilgi  
3. BaÅŸka baÄŸlamda doÄŸru olabilecek bilgi
4. YaygÄ±n yanÄ±lgÄ±lar

**KaÃ§Ä±nÄ±lacaklar:**
- SaÃ§ma, alakasÄ±z ÅŸÄ±klar âŒ
- Ã‡ok kolay eleme âŒ
- Metinde hiÃ§ geÃ§meyen kavramlar âŒ

## Ã‡IKTI FORMATI

SADECE bu JSON formatÄ±nda dÃ¶ndÃ¼r (baÅŸka hiÃ§bir ÅŸey yazma):

{{"metin": "Metin buraya ({min_w}-{max_w} kelime)", "soru": "Soru metni", "sik_a": "A ÅŸÄ±kkÄ±", "sik_b": "B ÅŸÄ±kkÄ±", "sik_c": "C ÅŸÄ±kkÄ±", "sik_d": "D ÅŸÄ±kkÄ±", "dogru_cevap": "A"}}

## Ã–NEMLÄ° HATIRLATMALAR

1. Metin {min_w}-{max_w} kelime OLMALIDIR (daha az veya fazla KABUL EDÄ°LMEZ)
2. SADECE JSON dÃ¶ndÃ¼r (aÃ§Ä±klama, yorum YOK)
3. SADECE TÃœRKÃ‡E (baÅŸka dil YOK)
4. LGS standartlarÄ±na UYGUN olmalÄ±

ÅÄ°MDÄ° BAÅLA - SADECE JSON DÃ–NDÃœR!"""
    
    return prompt

def validate_question(data_obj, spec):
    """
    SÄ±kÄ± kalite kontrolÃ¼
    
    Returns: (is_valid, reason, word_count)
    """
    
    # Required fields check
    required = ["metin", "soru", "sik_a", "sik_b", "sik_c", "sik_d", "dogru_cevap"]
    for field in required:
        if field not in data_obj or not data_obj[field]:
            return False, f"Missing: {field}", 0
    
    metin = data_obj["metin"]
    soru = data_obj["soru"]
    
    # Word count check (STRICT)
    wc = count_words(metin)
    min_w = spec["min_words"]
    max_w = spec["max_words"]
    
    # Â±10% tolerance (Ã§ok strict olmasÄ±n)
    tolerance = 0.1
    min_tolerant = int(min_w * (1 - tolerance))
    max_tolerant = int(max_w * (1 + tolerance))
    
    if wc < min_tolerant:
        return False, f"Too short: {wc} < {min_tolerant}", wc
    if wc > max_tolerant:
        return False, f"Too long: {wc} > {max_tolerant}", wc
    
    # Format check (numbered vs paragraph)
    has_numbered = bool(re.search(r'\b[IVX]+\.\s', metin))
    if spec["numbered"] and not has_numbered:
        return False, "NumaralÄ± cÃ¼mle yok", wc
    if not spec["numbered"] and has_numbered:
        return False, "NumaralÄ± cÃ¼mle olmamalÄ±", wc
    
    # Language check (no Chinese/Arabic/etc)
    has_chinese = any(0x4E00 <= ord(c) <= 0x9FFF for c in metin + soru)
    has_arabic = any(0x0600 <= ord(c) <= 0x06FF for c in metin + soru)
    
    if has_chinese or has_arabic:
        return False, "Foreign language detected", wc
    
    # DoÄŸru cevap check
    if data_obj["dogru_cevap"] not in ["A", "B", "C", "D"]:
        return False, "Invalid dogru_cevap", wc
    
    return True, "OK", wc

def generate_balanced_dataset(
    existing_data_path, 
    output_path, 
    target_per_type=30,
    max_retries_per_question=3
):
    """
    Dengeli sentetik veri Ã¼ret.
    
    Args:
        existing_data_path: Mevcut veri (daÄŸÄ±lÄ±m analizi iÃ§in)
        output_path: Ã‡Ä±ktÄ± dosyasÄ±
        target_per_type: Her soru tipi iÃ§in hedef sayÄ±
        max_retries_per_question: Her soru iÃ§in max deneme
    """
    
    # Mevcut daÄŸÄ±lÄ±mÄ± analiz et
    existing_counts = Counter()
    
    if Path(existing_data_path).exists():
        with open(existing_data_path, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    ex = json.loads(line.strip())
                    user = ex.get("user", "")
                    if "Konu:" in user and "Alt Konu:" in user:
                        konu = user.split("Konu:")[1].split("\n")[0].strip()
                        alt_konu = user.split("Alt Konu:")[1].split("\n")[0].strip()
                        key = f"{konu}_{alt_konu}"
                        existing_counts[key] += 1
                except:
                    pass
    
    print(f"\n{'='*70}")
    print(f"PROFESYONEL SENTETÄ°K VERÄ° ÃœRETÄ°CÄ°SÄ° v2")
    print(f"{'='*70}")
    print(f"Mevcut veri: {existing_data_path}")
    print(f"Ã‡Ä±ktÄ±: {output_path}")
    print(f"Hedef: Her soru tipi iÃ§in {target_per_type} Ã¶rnek")
    print(f"{'='*70}\n")
    
    # Ãœretim planÄ±
    generation_plan = {}
    
    for question_type, spec in QUESTION_TYPE_SPECS.items():
        current_count = existing_counts.get(question_type, 0)
        need = max(0, target_per_type - current_count)
        
        if need > 0:
            generation_plan[question_type] = need
            print(f"ğŸ“ {question_type:40s}: Mevcut={current_count:3d}, Hedef={target_per_type:3d}, Ãœretilecek={need:3d}")
    
    if not generation_plan:
        print("\nâœ… TÃ¼m soru tipleri hedef sayÄ±da! Ãœretim gerekmiyor.")
        return
    
    total_to_generate = sum(generation_plan.values())
    print(f"\n{'='*70}")
    print(f"TOPLAM ÃœRETÄ°LECEK: {total_to_generate} Ã¶rnek")
    print(f"{'='*70}\n")
    
    # Ãœretim baÅŸlasÄ±n
    generated = []
    total_success = 0
    total_attempts = 0
    
    for question_type, count_needed in generation_plan.items():
        konu, alt_konu = question_type.split("_", 1)
        spec = QUESTION_TYPE_SPECS[question_type]
        
        print(f"\n{'='*70}")
        print(f"Ãœretiliyor: {question_type}")
        print(f"{'='*70}")
        
        success_count = 0
        attempts = 0
        
        while success_count < count_needed and attempts < count_needed * max_retries_per_question:
            attempts += 1
            total_attempts += 1
            
            # Random tema
            import random
            tema = random.choice(TEMALAR)
            
            # Prompt oluÅŸtur
            prompt = build_professional_prompt(konu, alt_konu, tema, spec)
            
            # API Ã§aÄŸrÄ±sÄ±
            response = call_groq_api(prompt)
            
            if not response:
                print(f"   âŒ API failed (attempt {attempts})")
                continue
            
            # JSON parse
            try:
                start = response.find('{')
                end = response.rfind('}')
                if start == -1 or end == -1:
                    print(f"   âŒ No JSON found (attempt {attempts})")
                    continue
                
                data_obj = json.loads(response[start:end+1])
                
                # Validate
                is_valid, reason, wc = validate_question(data_obj, spec)
                
                if not is_valid:
                    print(f"   âŒ Validation failed: {reason} (attempt {attempts})")
                    continue
                
                # Success!
                success_count += 1
                total_success += 1
                
                # Save format
                generated.append({
                    "user": f"Konu: {konu}\\nAlt Konu: {alt_konu}\\n\\nBu kriterlere gÃ¶re LGS TÃ¼rkÃ§e sorusu Ã¼ret.",
                    "assistant": json.dumps(data_obj, ensure_ascii=False)
                })
                
                print(f"   âœ… Success {success_count}/{count_needed} | WC: {wc} | Attempt: {attempts}")
                
                # Rate limit korumasÄ±
                time.sleep(1)
                
            except json.JSONDecodeError as e:
                print(f"   âŒ JSON parse error: {str(e)} (attempt {attempts})")
                continue
            except Exception as e:
                print(f"   âŒ Unexpected error: {str(e)} (attempt {attempts})")
                continue
        
        print(f"\\n  ğŸ“Š {question_type}: {success_count}/{count_needed} baÅŸarÄ±lÄ± ({attempts} deneme)")
    
    # Kaydet
    print(f"\\n{'='*70}")
    print(f"KAYIT EDÄ°LÄ°YOR...")
    print(f"{'='*70}")
    
    with open(output_path, 'w', encoding='utf-8') as f:
        for example in generated:
            f.write(json.dumps(example, ensure_ascii=False) + '\\n')
    
    print(f"\\nâœ… {len(generated)} Ã¶rnek kaydedildi: {output_path}")
    print(f"\\n{'='*70}")
    print(f"Ã–ZET:")
    print(f"{'='*70}")
    print(f"Toplam deneme:  {total_attempts}")
    print(f"BaÅŸarÄ±lÄ±:       {total_success} ({100*total_success/total_attempts:.1f}%)")
    print(f"BaÅŸarÄ±sÄ±z:      {total_attempts - total_success}")
    print(f"{'='*70}")

if __name__ == "__main__":
    # Paths
    existing_train = project_dir / "data" / "v12_quality_filtered" / "train.jsonl"
    output_synthetic = project_dir / "data" / "synthetic_v2" / "train_synthetic.jsonl"
    
    output_synthetic.parent.mkdir(exist_ok=True)
    
    # Ãœret
    generate_balanced_dataset(
        existing_data_path=existing_train,
        output_path=output_synthetic,
        target_per_type=30,  # Her soru tipi iÃ§in 30 Ã¶rnek
        max_retries_per_question=5  # Max 5 deneme per soru
    )
