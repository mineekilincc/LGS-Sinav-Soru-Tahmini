{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸš€ LGS Model API V11 - PROBLEM Ã‡Ã–ZÃœM VERSÄ°YONU\n",
                "\n",
                "## âœ… TÃ¼m Problemler Ä°Ã§in Ã‡Ã¶zÃ¼m:\n",
                "- âœ… Temperature 0.35 (halÃ¼sinasyon Ã¶nleme)\n",
                "- âœ… Repetition Penalty 1.5 (dÃ¶ngÃ¼ Ã¶nleme)\n",
                "- âœ… No Repeat N-gram 4 (tekrar engelleme)\n",
                "- âœ… Top-K 30 (odaklÄ± seÃ§im)\n",
                "- âœ… Sert System Prompt (format kontrol)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Kurulum\n",
                "print(\"â³ Kurulum...\")\n",
                "!pip install -q --no-deps \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
                "!pip install -q unsloth_zoo\n",
                "!pip install -q --no-deps xformers trl peft accelerate bitsandbytes\n",
                "!pip install -q flask requests\n",
                "\n",
                "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
                "!dpkg -i cloudflared-linux-amd64.deb\n",
                "print(\"âœ… Kurulum tamamlandÄ±!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "MODEL_PATH = \"/content/drive/MyDrive/lgs_soru_tahmin_projesi/models/lgs_qwen_32b_v10\"\n",
                "\n",
                "import os\n",
                "if os.path.exists(MODEL_PATH):\n",
                "    print(f\"âœ… Model bulundu: {MODEL_PATH}\")\n",
                "else:\n",
                "    print(f\"âŒ Model bulunamadÄ±! Ã–nce eÄŸitimi tamamlayÄ±n.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Model YÃ¼kleme\n",
                "from unsloth import FastLanguageModel\n",
                "import torch\n",
                "\n",
                "print(\"â³ Model yÃ¼kleniyor...\")\n",
                "model, tokenizer = FastLanguageModel.from_pretrained(\n",
                "    model_name = MODEL_PATH,\n",
                "    max_seq_length = 2048,\n",
                "    dtype = None,\n",
                "    load_in_4bit = True,\n",
                ")\n",
                "FastLanguageModel.for_inference(model)\n",
                "print(f\"âœ… Model yÃ¼klendi! VRAM: {torch.cuda.memory_allocated()/1024**3:.1f} GB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. SERT System Prompt V11 (TÃ¼m Problemler Ä°Ã§in)\n",
                "SYSTEM_PROMPT = \"\"\"Sen MEB LGS TÃ¼rkÃ§e soru yazarÄ±sÄ±n.\n",
                "\n",
                "â›” MUTLAK YASAKLAR (Ä°HLAL ETTÄ°ÄÄ°NDE SIFIR PUAN!):\n",
                "1. UYDURMA kavram/terim KULLANMA! Sadece GERÃ‡EK, BÄ°LÄ°NEN bilgiler!\n",
                "2. AynÄ± cÃ¼mleyi TEKRAR etme, dÃ¶ngÃ¼ye GÄ°RME!\n",
                "3. JSON dÄ±ÅŸÄ±nda TEK KARAKTER yazma!\n",
                "\n",
                "âœ… METÄ°N FORMATI KURALLARI:\n",
                "- \"Ana DÃ¼ÅŸÃ¼nce\", \"BaÅŸlÄ±k Bulma\", \"AnlatÄ±m BiÃ§imi\" â†’ PARAGRAF (80-120 kelime)\n",
                "- \"Ã‡ok AnlamlÄ±lÄ±k\", \"Deyim\", \"Fiilimsiler\", \"KoÅŸul\" â†’ 4 KISA CÃœMLE (I, II, III, IV)\n",
                "\n",
                "âœ… HEDEF KELÄ°ME GÃ–STERÄ°MÄ°:\n",
                "- Ã‡ok AnlamlÄ±lÄ±k: Kelime TÄ°RNAK iÃ§inde â†’ \"gÃ¶z\", \"el\"\n",
                "- Deyim: Deyim TÄ°RNAK iÃ§inde â†’ \"gÃ¶z kulak olmak\"\n",
                "- Fiilimsiler: Fiilimsi TÄ°RNAK iÃ§inde â†’ \"koÅŸan\"\n",
                "\n",
                "âœ… ÅIK KURALLARI:\n",
                "- 4 ÅŸÄ±k (A, B, C, D), benzer uzunluk\n",
                "- dogru_cevap SADECE: A, B, C veya D\n",
                "- UYDURMA ÅŸÄ±k YASAK!\n",
                "\n",
                "JSON:\n",
                "{\"metin\": \"...\", \"soru\": \"...\", \"sik_a\": \"...\", \"sik_b\": \"...\", \"sik_c\": \"...\", \"sik_d\": \"...\", \"dogru_cevap\": \"A\"}\"\"\"\n",
                "\n",
                "print(\"âœ… Sert System Prompt V11 hazÄ±r\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. API Servisi (V11 - OPTÄ°MÄ°ZE PARAMETRELER)\n",
                "from flask import Flask, request, jsonify\n",
                "import threading\n",
                "import time\n",
                "import subprocess\n",
                "import re\n",
                "\n",
                "app = Flask(__name__)\n",
                "\n",
                "@app.route('/generate', methods=['POST'])\n",
                "def generate():\n",
                "    data = request.json\n",
                "    prompt = data.get('prompt', '')\n",
                "    \n",
                "    if isinstance(prompt, dict):\n",
                "        user_content = prompt.get(\"user\", \"\")\n",
                "    else:\n",
                "        user_content = prompt\n",
                "\n",
                "    if not user_content:\n",
                "        return jsonify({'error': 'No prompt'}), 400\n",
                "    \n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
                "        {\"role\": \"user\", \"content\": user_content}\n",
                "    ]\n",
                "    \n",
                "    inputs = tokenizer.apply_chat_template(\n",
                "        messages,\n",
                "        tokenize=True,\n",
                "        add_generation_prompt=True,\n",
                "        return_tensors=\"pt\"\n",
                "    ).to(\"cuda\")\n",
                "    \n",
                "    input_length = inputs.shape[-1]\n",
                "    attention_mask = torch.ones_like(inputs)\n",
                "    \n",
                "    # V11 OPTÄ°MÄ°ZE PARAMETRELER - TÃ¼m problemler iÃ§in\n",
                "    outputs = model.generate(\n",
                "        inputs,\n",
                "        attention_mask=attention_mask,\n",
                "        max_new_tokens=600,           # Daha kÄ±sa, dÃ¶ngÃ¼ Ã¶nleme\n",
                "        temperature=0.35,             # HalÃ¼sinasyon Ã¶nleme\n",
                "        do_sample=True,\n",
                "        top_p=0.8,                    # Daha odaklÄ±\n",
                "        top_k=30,                     # Daha sÄ±nÄ±rlÄ± seÃ§im\n",
                "        repetition_penalty=1.5,       # GÃ¼Ã§lÃ¼ tekrar cezasÄ±\n",
                "        no_repeat_ngram_size=4,       # 4-gram tekrarÄ±nÄ± engelle\n",
                "        pad_token_id=tokenizer.eos_token_id,\n",
                "    )\n",
                "    \n",
                "    # Sadece yeni tokenlarÄ± decode et\n",
                "    new_tokens = outputs[0][input_length:]\n",
                "    response = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
                "    \n",
                "    return jsonify({'result': response})\n",
                "\n",
                "@app.route('/health', methods=['GET'])\n",
                "def health():\n",
                "    return jsonify({'status': 'ok', 'model': 'LGS V11 Problem Fix'})\n",
                "\n",
                "threading.Thread(target=app.run, kwargs={'port': 5000}).start()\n",
                "print(\"âœ… Flask API V11 baÅŸlatÄ±ldÄ±\")\n",
                "print(\"   temp=0.35, rep_penalty=1.5, no_repeat=4\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Cloudflare Tunnel\n",
                "print(\"ğŸš€ Tunnel aÃ§Ä±lÄ±yor...\")\n",
                "\n",
                "process = subprocess.Popen(\n",
                "    ['cloudflared', 'tunnel', '--url', 'http://127.0.0.1:5000'],\n",
                "    stdout=subprocess.PIPE,\n",
                "    stderr=subprocess.PIPE\n",
                ")\n",
                "time.sleep(4)\n",
                "\n",
                "for _ in range(50):\n",
                "    line = process.stderr.readline().decode('utf-8')\n",
                "    if not line: break\n",
                "    match = re.search(r'https://[a-zA-Z0-9-]+\\.trycloudflare\\.com', line)\n",
                "    if match:\n",
                "        url = match.group(0)\n",
                "        print(\"=\"*60)\n",
                "        print(f\"ğŸ”— API URL: {url}\")\n",
                "        print(\"=\"*60)\n",
                "        print(f\"\\n.env dosyasÄ±na ekleyin:\\nCOLAB_API_URL={url}\")\n",
                "        break"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Test - Ã‡ok AnlamlÄ±lÄ±k (4 cÃ¼mle formatÄ± kontrolÃ¼)\n",
                "import requests\n",
                "import json\n",
                "\n",
                "test_prompt = \"\"\"Konu: SÃ¶zcÃ¼kte Anlam\n",
                "Alt Konu: Ã‡ok AnlamlÄ±lÄ±k\n",
                "\n",
                "## Ã‡OK ANLAMLILIK KILAVUZU\n",
                "\n",
                "**METÄ°N FORMATI:** 4 BAÄIMSIZ CÃœMLE (I, II, III, IV ile numaralandÄ±rÄ±lmÄ±ÅŸ)\n",
                "**HEDEF KELÄ°ME:** Her cÃ¼mlede TÄ°RNAK iÃ§inde: \"gÃ¶z\", \"el\", \"baÅŸ\"\n",
                "\n",
                "â›” YASAKLAR:\n",
                "- Paragraf formatÄ± KULLANMA!\n",
                "- UYDURMA kavram KULLANMA!\n",
                "\n",
                "SADECE JSON dÃ¶ndÃ¼r!\"\"\"\n",
                "\n",
                "response = requests.post(\n",
                "    \"http://127.0.0.1:5000/generate\",\n",
                "    json={\"prompt\": {\"user\": test_prompt}}\n",
                ")\n",
                "\n",
                "if response.status_code == 200:\n",
                "    result = response.json().get(\"result\", \"\")\n",
                "    print(\"âœ… Test baÅŸarÄ±lÄ±!\")\n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(result)\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    # Format kontrolÃ¼\n",
                "    if \"I.\" in result or \"I)\" in result:\n",
                "        print(\"\\nâœ… 4 CÃœMLE FORMATI DOÄRU!\")\n",
                "    else:\n",
                "        print(\"\\nâš ï¸ 4 cÃ¼mle formatÄ± bulunamadÄ±\")\n",
                "else:\n",
                "    print(f\"âŒ Hata: {response.status_code}\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "A100",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}